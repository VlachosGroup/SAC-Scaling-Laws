{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training the Single Atom Diffusion Scaling Law in Python\n",
    "\n",
    "Author: Yifan Wang [(wangyf@udel.edu)](wangyf@udel.edu)\n",
    "\n",
    "The scaling law correlates the diffusion activation energy for support single atoms on the support with physcial descriptors\n",
    "\n",
    "The form of the scaling law is obtained from various machine learning methods and the traing procedure is shown below.\n",
    "\n",
    "The primary physical descriptors (features) include \n",
    "\n",
    "- Ec (cohesive energy of the metal)  \n",
    "\n",
    "- Ebind (the binding energy of the single atom)\n",
    "\n",
    "The secondary descriptors are the polynomial terms (orders from -2 to 2) of the primary descriptors  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Import all libraries \n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    " \n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import (ElasticNet, ElasticNetCV, Lasso, LassoCV,\n",
    "                                  Ridge, RidgeCV, enet_path, lasso_path)\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import (LeaveOneOut, RepeatedKFold,\n",
    "                                     cross_val_score, train_test_split)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "\n",
    "# import customized plotting functions\n",
    "import regression_tools as rtools\n",
    "\n",
    "# Set plotting format\n",
    "font = {'size'   : 20}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rcParams['axes.linewidth'] = 1.5\n",
    "matplotlib.rcParams['xtick.major.size'] = 12\n",
    "matplotlib.rcParams['xtick.labelsize'] = 16\n",
    "matplotlib.rcParams['ytick.labelsize'] = 16\n",
    "matplotlib.rcParams['xtick.major.width'] = 3\n",
    "matplotlib.rcParams['ytick.major.size'] = 12\n",
    "matplotlib.rcParams['ytick.major.width'] = 3\n",
    "matplotlib.rcParams['legend.fontsize'] = 16\n",
    "matplotlib.rcParams['figure.dpi'] = 300. # set plotting resolution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Import adsorption data from a csv file\n",
    "\n",
    "data = pd.read_csv('Ea_data.csv', header = 0)\n",
    "\n",
    "metal = np.array(data['metal'])\n",
    "support = np.array(data['support'])\n",
    "Ec = np.array(data['Ec']) # cohesive energy of the metal\n",
    "Ebind = np.array(data['Ebind']) #binding energy of the single atom\n",
    "Ea = np.array(data['Ea']) # Diffusion barrier of the single atom onto the support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Prepare for the descriptors (features) \n",
    "\n",
    "# Numerical orders\n",
    "orders = [1, -1, 0.5, -0.5, 2, -2]\n",
    "\n",
    "\n",
    "def transformers(xv, orders):\n",
    "\n",
    "    '''\n",
    "    Transform each column of primary featurs into secondary features\n",
    "    '''\n",
    "    x_features = np.reshape(xv, (len(xv),1))\n",
    "    \n",
    "    for oi in orders[1:]:\n",
    "        x_features = np.concatenate((x_features, np.reshape(xv, (len(xv),1))**oi), axis = 1)\n",
    "    \n",
    "    '''\n",
    "    Add additional features\n",
    "    '''\n",
    "    x_features = np.concatenate((x_features, np.log(np.reshape(xv, (len(xv),1)))), axis = 1)\n",
    "    \n",
    "    return x_features\n",
    "'''\n",
    "Get the names and orders\n",
    "'''    \n",
    "# primary and secondary feature names\n",
    "x_primary_feature_names = ['Ec', 'Ebind']\n",
    "x_secondary_feature_names_2d = []\n",
    "orders_log = orders + ['ln']\n",
    "\n",
    "# The number for all numerical opeators \n",
    "all_orders_log = []\n",
    "\n",
    "for xi in x_primary_feature_names:  \n",
    "    x_secondary_feature_names_2d.append([xi + '_' + str(oi) for oi in orders_log])\n",
    "    all_orders_log += orders_log\n",
    "    \n",
    "x_secondary_feature_names = []\n",
    "for xi in x_secondary_feature_names_2d:\n",
    "    x_secondary_feature_names += xi\n",
    "\n",
    "\n",
    "'''\n",
    "Apply to the data\n",
    "''' \n",
    "Ec_features = transformers(Ec, orders)    \n",
    "Ebind_features = transformers(Ebind, orders)   \n",
    "\n",
    "\n",
    "X_init = np.concatenate((Ec_features, Ebind_features),axis = 1) \n",
    "\n",
    "\n",
    "poly = PolynomialFeatures(2, interaction_only=True)\n",
    "X_poly = poly.fit_transform(X_init)\n",
    "orders_m = poly.powers_\n",
    "\n",
    "'''\n",
    "Select nonzero features\n",
    "'''\n",
    "x_features_poly = ['1'] # nonzero feature names in a 2d list\n",
    "poly_indices_nonrepeat = [0] # indices in the polynominal order matrix \n",
    "#Create feature names for plotting\n",
    "x_plot_feature_names = ['b'] + x_secondary_feature_names\n",
    "x_plot_feature_names = ['1', r'$\\rm E_c$', r'$\\rm E_c^{-1}$', r'$\\rm E_c^{0.5}$', r'$\\rm E_c^{-0.5}$',  r'$\\rm E_c^2$', r'$\\rm E_c^{-2}$', r'$\\rm ln(E_c)$', r'$\\rm E_{bind}$',\n",
    "         r'$\\rm E_{bind}^{-1}$', r'$\\rm E_{bind}^{0.5}$', r'$\\rm E_{bind}^{-0.5}$', r'$\\rm E_{bind}^2$', r'$\\rm E_{bind}^{-2}$', \n",
    "         r'$\\rm ln(E_{bind})$']\n",
    "\n",
    "n_features = len(x_plot_feature_names)\n",
    "\n",
    "\n",
    "'''\n",
    "Get the indices and feature names for nonzero features, \n",
    "namely with nonzero order\n",
    "'''\n",
    "for pi, powers in enumerate(poly.powers_):\n",
    "    \n",
    "    powers_nonzero = (powers > 0).nonzero()[0]\n",
    "    \n",
    "    if not list(powers_nonzero) == []:\n",
    "        \n",
    "        features_nonzero = [x_secondary_feature_names[pi] for pi in powers_nonzero]\n",
    "        orders_nonzero = np.array([all_orders_log[pi] for pi in powers_nonzero])\n",
    "    \n",
    "        try: \n",
    "            # making sure the zero sum is from one feature each\n",
    "            ordersum = orders_nonzero.sum()\n",
    "            f1_order = powers_nonzero[0] in range(0, len(x_secondary_feature_names_2d[0]))\n",
    "            f2_order = powers_nonzero[1] in range(len(x_secondary_feature_names_2d[0]), len(x_secondary_feature_names_2d[0])+len(x_secondary_feature_names_2d[1]))\n",
    "        \n",
    "            if ordersum == 0:\n",
    "                if (f1_order and f2_order):\n",
    "                    x_features_poly.append(features_nonzero)\n",
    "                    poly_indices_nonrepeat.append(pi)\n",
    "       \n",
    "            else:\n",
    "                    x_features_poly.append(features_nonzero)\n",
    "                    poly_indices_nonrepeat.append(pi)\n",
    "       \n",
    "        except:\n",
    "            \n",
    "            x_features_poly.append(features_nonzero)\n",
    "            poly_indices_nonrepeat.append(pi)\n",
    "\n",
    "poly_indices_nonrepeat = np.array(poly_indices_nonrepeat)\n",
    "\n",
    "\n",
    "x_features_poly_combined = []\n",
    "for fi in x_features_poly:\n",
    "    if len(fi) > 1:\n",
    "        fi_combined = []\n",
    "        for fj in fi:\n",
    "            fi_combined += fj\n",
    "            fi_combined = ''.join(fi_combined)\n",
    "\n",
    "        x_features_poly_combined.append(fi_combined)\n",
    "        \n",
    "    else: x_features_poly_combined.append(fi[0])\n",
    "\n",
    "\n",
    "'''\n",
    "Additional Screening, take out repeated features \n",
    "'''\n",
    "repeated_indices = [16, 18, 27, 29, 40, 49, 83, 85, 87, 89, 93, 95]\n",
    "poly_indices_nonrepeat = [poly_indices_nonrepeat[i] for i in range(0, len(poly_indices_nonrepeat)) if i not in repeated_indices]\n",
    "x_features_poly_combined = [x_features_poly_combined[i] for i in range(0, len(x_features_poly_combined)) if i not in repeated_indices]\n",
    "x_features_poly = [x_features_poly[i] for i in range(0, len(x_features_poly)) if i not in repeated_indices]\n",
    "\n",
    "\n"
   ]
  }
 ]
}